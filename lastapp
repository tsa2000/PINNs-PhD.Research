import os
import time

# ==========================================
# 1. ØªÙ†Ø¸ÙŠÙ
# ==========================================
!pkill cloudflared
!pkill streamlit
!rm -f nohup.out

# ==========================================
# 2. ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ "Ù…Ø­Ù„Ù„ Ø§Ù„Ø²Ù…Ù†" (Time Parser)
# ==========================================
app_code = """
import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import plotly.graph_objs as go
import re

st.set_page_config(page_title="Smart Battery Agent", layout="wide", initial_sidebar_state="collapsed")

# --- CSS ---
st.markdown(\"\"\"
<style>
    .block-container {padding-top: 1rem; padding-bottom: 5rem;}
    .stChatInput {position: fixed; bottom: 0; left: 0; right: 0; padding: 1rem; background: white; z-index: 100;}
</style>
\"\"\", unsafe_allow_html=True)

# --- Model ---
class BatteryPINN_Uncertainty(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 128), nn.Tanh(),
            nn.Dropout(0.05),  
            nn.Linear(128, 128), nn.Tanh(),
            nn.Dropout(0.05),
            nn.Linear(128, 128), nn.Tanh(),
            nn.Linear(128, 1)
        )
    def forward(self, t, v):
        TIME_SCALE, T_SCALE, V_SCALE = 60.0, 1000.0, 200.0
        inputs = torch.cat([t/TIME_SCALE, v/V_SCALE], dim=1)
        return self.net(inputs) * T_SCALE

@st.cache_resource
def load_model():
    model = BatteryPINN_Uncertainty()
    try:
        model.load_state_dict(torch.load("battery_pinn_uncertainty.pth", map_location=torch.device('cpu')))
        model.eval()
    except Exception as e:
        st.error(f"Error: {e}")
    return model

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© ---
def run_dynamic_simulation(model, velocity_profile, duration, n_samples=50):
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø²Ù…Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    t_vals = np.linspace(0, duration, len(velocity_profile))
    t_tensor = torch.tensor(t_vals, dtype=torch.float32).view(-1, 1)
    v_tensor = torch.tensor(velocity_profile, dtype=torch.float32).view(-1, 1)
    
    model.train() 
    preds = []
    with torch.no_grad():
        for _ in range(n_samples):
            preds.append(model(t_tensor, v_tensor).numpy().flatten())
    preds = np.array(preds)
    return t_vals, preds.mean(axis=0), preds.std(axis=0)

# --- ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø·ÙˆØ± (Advanced Brain) ---
def creative_agent(query, model):
    query = query.lower()
    points = 300 # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©
    
    # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø²Ù…Ù† (Duration)
    duration = 60.0 # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "10 minutes" Ø£Ùˆ "5 min"
    time_min_match = re.search(r'(\d+)\s*(min|minutes)', query)
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "100 seconds" Ø£Ùˆ "30 s"
    time_sec_match = re.search(r'(\d+)\s*(s|sec|seconds)', query)
    
    time_str = "60s (Default)"
    
    if time_min_match:
        mins = float(time_min_match.group(1))
        duration = mins * 60.0 # ØªØ­ÙˆÙŠÙ„ Ù„Ø«ÙˆØ§Ù†ÙŠ
        time_str = f"{mins} minutes ({duration:.0f}s)"
    elif time_sec_match:
        secs = float(time_sec_match.group(1))
        duration = secs
        time_str = f"{secs} seconds"

    t_base = np.linspace(0, duration, points)
    velocity_profile = None
    scenario_name = ""
    explanation = ""

    # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ---
    
    if "panic" in query or "stop" in query:
        scenario_name = "âš ï¸ Panic Stop Scenario"
        # ÙŠØªÙˆÙ‚Ù Ø¹Ù†Ø¯ Ø«Ù„Ø« Ø§Ù„ÙˆÙ‚Øª
        stop_time = duration / 3.0
        velocity_profile = np.ones(points) * 120.0 
        velocity_profile[t_base > stop_time] = 0.0 
        explanation = f"Simulating **Panic Stop** over **{time_str}**. \\nVelocity drops to 0 at t={stop_time:.1f}s."

    elif "rescue" in query or "accelerate" in query:
        scenario_name = "âœ… Aero-Cooling Rescue"
        start_time = duration / 4.0
        velocity_profile = np.zeros(points)
        velocity_profile[t_base > start_time] = 180.0 
        explanation = f"Simulating **Rescue Acceleration** over **{time_str}**. \\nVehicle accelerates at t={start_time:.1f}s."

    else:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø±Ø¹Ø©
        vel_match = re.search(r'(\d+)\s*(km|km/h|kph)?', query)
        # Ù†ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù„ÙŠØ³ Ù‡Ùˆ Ù†ÙØ³Ù‡ Ø±Ù‚Ù… Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ (Ø®Ø¯Ø¹Ø© regex)
        
        # ØªØ­Ø³ÙŠÙ†: Ù†Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆÙ†Ø­Ù„Ù„ Ø³ÙŠØ§Ù‚Ù‡Ø§
        numbers = re.findall(r'(\d+)', query)
        velocity = 0.0
        
        # Ù…Ù†Ø·Ù‚ Ø¨Ø³ÙŠØ·: Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø±Ù‚Ù…ÙŠÙ†ØŒ Ø£Ø­Ø¯Ù‡Ù…Ø§ Ù„Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø¢Ø®Ø± Ù„Ù„Ø³Ø±Ø¹Ø©
        # Ø³Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…Ø¬Ø§ÙˆØ± Ù„Ù€ km/h Ù„ÙŠÙƒÙˆÙ† Ø£Ø¯Ù‚
        vel_specific = re.search(r'(\d+)\s*(km|km/h)', query)
        
        if vel_specific:
            velocity = float(vel_specific.group(1))
        elif len(numbers) > 0:
            # ØªØ®Ù…ÙŠÙ†: Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ÙˆØ­Ø¯Ø©ØŒ Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ø±Ù‚Ù… Ù„ÙŠØ³ Ù‡Ùˆ Ø±Ù‚Ù… Ø§Ù„ÙˆÙ‚Øª
            for num in numbers:
                if float(num) != (duration/60.0 if "min" in query else duration):
                    velocity = float(num)
                    break
            if velocity == 0 and len(numbers)==1 and "min" not in query and "sec" not in query:
                 velocity = float(numbers[0]) # Ø§Ù„Ø±Ù‚Ù… Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ Ø§Ù„Ø³Ø±Ø¹Ø©

        if velocity > 0 or "0 km" in query:
            scenario_name = f"ğŸš— Constant Velocity: {velocity} km/h"
            velocity_profile = np.full(points, velocity)
            explanation = f"Simulating cruising at **{velocity} km/h** for **{time_str}**."
        else:
             return "I understood the time, but not the speed. Try: '100 km/h for 10 minutes'.", None, None, None, None, None

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    t, mean, std = run_dynamic_simulation(model, velocity_profile, duration)
    return explanation, t, mean, std, velocity_profile, scenario_name

# --- UI ---
st.title("ğŸ¤– Time-Aware AI Agent")
st.caption("Try: '100 km/h for 10 minutes' or 'Panic stop for 120 seconds'")

model = load_model()

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "figure" in msg:
            st.plotly_chart(msg["figure"], use_container_width=True)

if prompt := st.chat_input("Ex: 'Cruise at 100 km/h for 5 minutes'"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Analyzing Physics..."):
            explanation, t, mean, std, v_profile, title = creative_agent(prompt, model)
            
            if t is not None:
                st.markdown(f"**{title}**")
                st.markdown(explanation)
                
                fig = go.Figure()
                # Uncertainty
                fig.add_trace(go.Scatter(
                    x=np.concatenate([t, t[::-1]]),
                    y=np.concatenate([mean+2*std, (mean-2*std)[::-1]]),
                    fill='toself', fillcolor='rgba(255,0,0,0.2)', line=dict(color='rgba(255,255,255,0)'),
                    name='Uncertainty'
                ))
                # Temp
                fig.add_trace(go.Scatter(x=t, y=mean, name='Temperature', line=dict(color='red', width=3)))
                # Velocity (Secondary Axis)
                fig.add_trace(go.Scatter(x=t, y=v_profile, name='Velocity', line=dict(color='blue', dash='dot'), yaxis='y2'))
                
                fig.update_layout(
                    xaxis_title="Time (seconds)",
                    yaxis=dict(title="Temp (Â°C)"),
                    yaxis2=dict(title="Vel (km/h)", overlaying='y', side='right', range=[0, 250]),
                    height=350, margin=dict(l=10, r=10, t=30, b=10),
                    legend=dict(orientation="h", y=1.1)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                st.session_state.messages.append({"role": "assistant", "content": explanation, "figure": fig})
            else:
                st.markdown(explanation)
                st.session_state.messages.append({"role": "assistant", "content": explanation})
"""

with open("app.py", "w") as f:
    f.write(app_code)

print("âœ… Time-Aware Agent Ready!")

# ==========================================
# 3. Launch
# ==========================================
import urllib
!pip install -q streamlit
!wget -q -O cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64
!chmod +x cloudflared
!nohup ./cloudflared tunnel --url http://localhost:8501 > nohup.out 2>&1 &
!nohup streamlit run app.py > streamlit.out 2>&1 &

time.sleep(5)
print("\nğŸ‘‡ CLICK HERE TO TEST TIME QUERIES ğŸ‘‡")
!grep -o 'https://.*\.trycloudflare.com' nohup.out 2>/dev/null | head -n 1
