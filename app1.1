import os
import time

# ==========================================
# 1. ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (app.py) Ù…Ø¨Ø§Ø´Ø±Ø©
# ==========================================
app_code = """
import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import plotly.graph_objs as go

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ ---
st.set_page_config(
    page_title="Battery AI Twin",
    layout="wide",
    page_icon="ğŸ”‹",
    initial_sidebar_state="collapsed"
)

# --- CSS Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¶ Ø¹Ù„Ù‰ Ø³ÙØ§Ø±ÙŠ ÙˆØ§Ù„Ù‡ÙˆØ§ØªÙ ---
st.markdown(\"\"\"
<style>
    .block-container {padding-top: 1rem; padding-bottom: 1rem;}
    .stMetric {background-color: #f0f2f6; padding: 10px; border-radius: 10px; text-align: center;}
    h1 {font-size: 1.5rem !important;}
</style>
\"\"\", unsafe_allow_html=True)

# --- ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (128 Neurons + Dropout) ---
class BatteryPINN_Uncertainty(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 128), nn.Tanh(),
            nn.Dropout(0.05),  
            nn.Linear(128, 128), nn.Tanh(),
            nn.Dropout(0.05),
            nn.Linear(128, 128), nn.Tanh(),
            nn.Linear(128, 1)
        )

    def forward(self, t, v):
        TIME_SCALE, T_SCALE, V_SCALE = 60.0, 1000.0, 200.0
        inputs = torch.cat([t/TIME_SCALE, v/V_SCALE], dim=1)
        return self.net(inputs) * T_SCALE

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
@st.cache_resource
def load_model():
    model = BatteryPINN_Uncertainty()
    try:
        model.load_state_dict(torch.load("battery_pinn_uncertainty.pth", map_location=torch.device('cpu')))
        model.eval()
    except Exception as e:
        st.error(f"Error: {e}")
    return model

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© ---
def get_mc_predictions(model, t_tensor, v_tensor, n_samples=50):
    model.train() # ØªÙØ¹ÙŠÙ„ Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ†
    preds = []
    with torch.no_grad():
        for _ in range(n_samples):
            preds.append(model(t_tensor, v_tensor).numpy().flatten())
    preds = np.array(preds)
    return preds.mean(axis=0), preds.std(axis=0)

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Mobile Layout) ---
st.title("ğŸ”‹ 18650 AI Digital Twin")
st.caption("PhD Demonstrator | PINN + Uncertainty")

model = load_model()

# ÙˆØ¶Ø¹Ù†Ø§ Ø§Ù„ØªØ­ÙƒÙ… Ø¯Ø§Ø®Ù„ Expander
with st.expander("âš™ï¸ Scenario Settings (Click to Edit)", expanded=True):
    velocity = st.slider("ğŸš— Velocity (km/h)", 0, 200, 0)
    time_range = st.slider("â±ï¸ Duration (s)", 10, 60, 60)

if model:
    t_tensor = torch.linspace(0, time_range, 200).view(-1, 1)
    v_tensor = torch.full_like(t_tensor, float(velocity))
    t_plot = t_tensor.numpy().flatten()
    
    with st.spinner('Running Simulation...'):
        mean, std = get_mc_predictions(model, t_tensor, v_tensor)
    
    # Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
    fig = go.Figure()
    
    # Ø§Ù„Ø¸Ù„
    fig.add_trace(go.Scatter(
        x=np.concatenate([t_plot, t_plot[::-1]]),
        y=np.concatenate([mean+2*std, (mean-2*std)[::-1]]),
        fill='toself',
        fillcolor='rgba(255, 0, 0, 0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        showlegend=False
    ))
    
    # Ø§Ù„Ø®Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    fig.add_trace(go.Scatter(
        x=t_plot, y=mean,
        mode='lines',
        name='Temp',
        line=dict(color='#d62728', width=3)
    ))
    
    fig.update_layout(
        margin=dict(l=10, r=10, t=30, b=10),
        xaxis_title="Time (s)",
        yaxis_title="Temp (Â°C)",
        yaxis=dict(range=[0, 900]),
        height=350,
        template="plotly_white",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
    c1, c2 = st.columns(2)
    peak_val = mean.max()
    c1.metric("ğŸ”¥ Peak Temp", f"{peak_val:.0f}Â°C")
    c2.metric("ğŸ“‰ Cooling", "Active" if velocity > 0 else "None")

    # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ
    st.markdown("### ğŸ¤– AI Analyst Report")
    report_box = st.container()
    if velocity == 0:
        report_box.error(f"**CRITICAL:** Extreme heat (~{peak_val:.0f}Â°C). No cooling. High uncertainty.")
    elif velocity > 100:
        report_box.success(f"**OPTIMIZED:** Effective cooling. Temp suppressed by ~10-15Â°C.")
    else:
        report_box.warning(f"**TRANSITIONAL:** Moderate cooling. Increase velocity for better safety.")
"""

# ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù
with open("app.py", "w") as f:
    f.write(app_code)

print("âœ… App file created successfully!")

# ==========================================
# 2. Ø§Ù„ØªØ´ØºÙŠÙ„ (Install & Launch)
# ==========================================
print("ğŸ”— COPY THIS IP ADDRESS FOR PASSWORD:")
!curl ipv4.icanhazip.com
print("\nâ³ Installing dependencies & Launching Tunnel...")

!pip install -q streamlit localtunnel
!streamlit run app.py &>/dev/null&

# Ø§Ù†ØªØ¸Ø§Ø± Ù„Ø­Ø¸Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„Ø³ÙŠØ±ÙØ±
time.sleep(3)

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†ÙÙ‚
!npx localtunnel --port 8501
