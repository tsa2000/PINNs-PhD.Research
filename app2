import os
import time

# ==========================================
# 1. ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (app.py)
# ==========================================
app_code = """
import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import plotly.graph_objs as go

st.set_page_config(
    page_title="Battery AI Twin",
    layout="wide",
    page_icon="ğŸ”‹",
    initial_sidebar_state="collapsed"
)

st.markdown(\"\"\"
<style>
    .block-container {padding-top: 1rem; padding-bottom: 1rem;}
    .stMetric {background-color: #f0f2f6; padding: 10px; border-radius: 10px; text-align: center;}
    h1 {font-size: 1.5rem !important;}
</style>
\"\"\", unsafe_allow_html=True)

class BatteryPINN_Uncertainty(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 128), nn.Tanh(),
            nn.Dropout(0.05),  
            nn.Linear(128, 128), nn.Tanh(),
            nn.Dropout(0.05),
            nn.Linear(128, 128), nn.Tanh(),
            nn.Linear(128, 1)
        )

    def forward(self, t, v):
        TIME_SCALE, T_SCALE, V_SCALE = 60.0, 1000.0, 200.0
        inputs = torch.cat([t/TIME_SCALE, v/V_SCALE], dim=1)
        return self.net(inputs) * T_SCALE

@st.cache_resource
def load_model():
    model = BatteryPINN_Uncertainty()
    try:
        model.load_state_dict(torch.load("battery_pinn_uncertainty.pth", map_location=torch.device('cpu')))
        model.eval()
    except Exception as e:
        st.error(f"Error: {e}")
    return model

def get_mc_predictions(model, t_tensor, v_tensor, n_samples=50):
    model.train()
    preds = []
    with torch.no_grad():
        for _ in range(n_samples):
            preds.append(model(t_tensor, v_tensor).numpy().flatten())
    preds = np.array(preds)
    return preds.mean(axis=0), preds.std(axis=0)

st.title("ğŸ”‹ 18650 AI Digital Twin")
st.caption("PhD Demonstrator | PINN + Uncertainty")

model = load_model()

with st.expander("âš™ï¸ Scenario Settings (Click to Edit)", expanded=True):
    velocity = st.slider("ğŸš— Velocity (km/h)", 0, 200, 0)
    time_range = st.slider("â±ï¸ Duration (s)", 10, 60, 60)

if model:
    t_tensor = torch.linspace(0, time_range, 200).view(-1, 1)
    v_tensor = torch.full_like(t_tensor, float(velocity))
    t_plot = t_tensor.numpy().flatten()
    
    with st.spinner('Running Simulation...'):
        mean, std = get_mc_predictions(model, t_tensor, v_tensor)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=np.concatenate([t_plot, t_plot[::-1]]),
        y=np.concatenate([mean+2*std, (mean-2*std)[::-1]]),
        fill='toself',
        fillcolor='rgba(255, 0, 0, 0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        showlegend=False
    ))
    
    fig.add_trace(go.Scatter(
        x=t_plot, y=mean,
        mode='lines',
        name='Temp',
        line=dict(color='#d62728', width=3)
    ))
    
    fig.update_layout(
        margin=dict(l=10, r=10, t=30, b=10),
        xaxis_title="Time (s)",
        yaxis_title="Temp (Â°C)",
        yaxis=dict(range=[0, 900]),
        height=350,
        template="plotly_white",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    c1, c2 = st.columns(2)
    peak_val = mean.max()
    c1.metric("ğŸ”¥ Peak Temp", f"{peak_val:.0f}Â°C")
    c2.metric("ğŸ“‰ Cooling", "Active" if velocity > 0 else "None")

    st.markdown("### ğŸ¤– AI Analyst Report")
    report_box = st.container()
    if velocity == 0:
        report_box.error(f"**CRITICAL:** Extreme heat (~{peak_val:.0f}Â°C). No cooling. High uncertainty.")
    elif velocity > 100:
        report_box.success(f"**OPTIMIZED:** Effective cooling. Temp suppressed by ~10-15Â°C.")
    else:
        report_box.warning(f"**TRANSITIONAL:** Moderate cooling. Increase velocity for better safety.")
"""

with open("app.py", "w") as f:
    f.write(app_code)

print("âœ… App file created successfully!")

# ==========================================
# 2. Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØµØ­Ø­ (Corrected Launch)
# ==========================================
print("ğŸ”— COPY THIS IP ADDRESS FOR PASSWORD:")
!curl ipv4.icanhazip.com
print("\nâ³ Installing dependencies...")

# Ø§Ù„ØªØµØ­ÙŠØ­: Ù†Ø«Ø¨Øª streamlit ÙÙ‚Ø· Ø¹Ø¨Ø± pip
!pip install -q streamlit

# Ø§Ù„ØªØµØ­ÙŠØ­: Ù†Ø«Ø¨Øª localtunnel Ø¹Ø¨Ø± npm Ù„ØªØ¬Ù†Ø¨ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ (y/n)
!npm install -g localtunnel

print("ğŸš€ Launching App...")
!streamlit run app.py &>/dev/null&

time.sleep(3)

# Ø§Ù„Ø¢Ù† Ø³ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† ØªÙˆÙ‚Ù
!npx localtunnel --port 8501
